---
title: "End_to_end"
author: "hetarth"
date: "2024-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown


```{r}
##############################################################
# Full R Script: 
# 1. Load and Prepare Data 
# 2. Split into Train and Test 
# 3. Run Bayesian Model (JAGS) on the Train Set 
# 4. Predict on Test Set and Compute R²
##############################################################

# Clear workspace
rm(list=ls())

##############################################################
# Load required libraries
##############################################################
library(ggplot2)     # For visualizations
library(dplyr)        # For data manipulation
library(rjags)        # For JAGS interface
library(coda)         # For MCMC diagnostics

##############################################################
# Read the data
##############################################################
file_path <- "C:/Users/chopr/Desktop/Statistics Subjects/STAT431-ThisYear/project/dataset/obesity_dataset_linear.csv"
obesity_data <- read.csv(file_path)

# Display the first few rows of the dataframe
head(obesity_data)

##############################################################
# Create BMI column (BMI = Weight / Height^2)
##############################################################
obesity_data <- obesity_data %>%
  mutate(BMI_cont = Weight / (Height ^ 2)) %>%
  mutate(BMI_squared = BMI_cont ^ 2) %>%
  select(-CALC, -CAEC) # Dropping specified columns

head(obesity_data)

##############################################################
# Convert select variables into factors
##############################################################
factor_vars <- c("Gender", "family_history_with_overweight", "FAVC", 
                 "SMOKE", "SCC", "MTRANS", "NObeyesdad")
obesity_data[factor_vars] <- lapply(obesity_data[factor_vars], factor)

str(obesity_data)

##############################################################
# Exploratory Plots (optional - won't affect functionality)
##############################################################
# Numeric and categorical variable distribution checks
numeric_vars <- sapply(obesity_data, is.numeric)
categorical_vars <- sapply(obesity_data, is.factor)

numeric_var_names <- names(obesity_data)[numeric_vars]
categorical_var_names <- names(obesity_data)[categorical_vars]

##############################################################
# Drop Weight, NObeyesdad columns as previously done
##############################################################
obesity_data <- obesity_data %>%
  select(-Weight, -NObeyesdad)

head(obesity_data)


##############################################################
# Data Preparation for JAGS
# Steps:
# 1. Convert categorical features to numeric (0-based)
# 2. Scale and standardize numeric features as before
# 3. Create predictor matrix X
##############################################################

# Convert categorical features to numeric (0-based)
categorical_features <- c("Gender", "family_history_with_overweight", "FAVC","SMOKE", "SCC", "MTRANS")
obesity_data[categorical_features] <- lapply(obesity_data[categorical_features], function(x) {
  numeric_values <- as.numeric(factor(x))
  numeric_values - min(numeric_values, na.rm = TRUE)
})

# Identify columns to scale (excluding Age, BMI_cont, group, MTRANS because group/MTRANS used for grouping)
columns_to_scale <- setdiff(names(obesity_data), c("Age", "BMI_squared", "group", "MTRANS"))

# Min-max scaling for selected columns
obesity_data[columns_to_scale] <- lapply(obesity_data[columns_to_scale], function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
})

# Standardize Age
obesity_data <- obesity_data %>%
  mutate(
    Age = (Age - mean(Age, na.rm = TRUE)) / sd(Age, na.rm = TRUE)
  )

# Define predictors
predictors <- c("Age", "Gender", "family_history_with_overweight", "FAVC",
                "SMOKE", "SCC", "FAF", "TUE", "CH2O", "NCP", "FCVC")

X <- as.matrix(obesity_data[, predictors])

# Create a group variable from MTRANS
obesity_data$group <- obesity_data$MTRANS  
obesity_data$group <- as.integer(as.factor(obesity_data$group))

# Final structure
N <- nrow(obesity_data)
P <- ncol(X)
J <- length(unique(obesity_data$group))

str(obesity_data)
cat("Dimensions of X:", dim(X), "\n")
cat("Number of Observations (N):", N, "\n")
cat("Number of Groups (J):", J, "\n")
cat("Number of Predictors (P):", P, "\n")

##############################################################
# Train-Test Split
##############################################################
set.seed(123) # For reproducibility
train_index <- sample(1:N, size = floor(0.7*N), replace = FALSE)
test_index <- setdiff(1:N, train_index)

obesity_train <- obesity_data[train_index, ]
obesity_test <- obesity_data[test_index, ]

X_train <- X[train_index, ]
X_test <- X[test_index, ]

N_train <- nrow(X_train)
N_test <- nrow(X_test)

J_train <- length(unique(obesity_train$group))
# Note: It's possible that test set doesn't have all groups present in training.
# For simplicity, we assume all groups in test are also in train.
# If not, you'd have to handle groups not seen in training (set u[group] = 0 or similar).

##############################################################
# Prepare Data for JAGS from the Training Set
##############################################################
jags_data <- list(
  N = N_train,
  J = J_train,
  BMI_squared = obesity_train$BMI_squared,
  X = X_train,
  group = obesity_train$group
)

##############################################################
# JAGS Model File (question_3.bug)
# We'll write it here as a temporary file
##############################################################
model_string <- "
model {
  # Likelihood
  for (i in 1:N) {
    BMI_squared[i] ~ dnorm(mu[i], tau_residual)
    mu[i] <- beta0 + inprod(X[i, ], beta[]) + u[group[i]]
    # For WAIC calculation
    likelihood[i] <- dnorm(BMI_squared[i], mu[i], tau_residual)
  }

  # Group effects
  for (j in 1:J) {
    u[j] ~ dnorm(0, tau_group)
  }

  # Priors for coefficients
  beta0 ~ dnorm(25, 0.001)

  beta[1] ~ dexp(0.04)      # Age
  beta[2] ~ dnorm(0, 0.001) # Gender
  beta[3] ~ dnorm(0, 0.001) # family_history_with_overweight
  beta[4] ~ dnorm(0, 0.001) # FAVC
  beta[5] ~ dnorm(0, 0.001) # SMOKE
  beta[6] ~ dnorm(0, 0.001) # SCC
  beta[7] ~ dnorm(0, 0.001) # FAF
  beta[8] ~ dnorm(0, 0.000001) # TUE
  beta[9] ~ dnorm(0, 0.000001) # CH2O
  beta[10] ~ dnorm(0, 0.001) # NCP
  beta[11] ~ dnorm(0, 0.001) # FCVC

  # Priors for variance
  tau_residual ~ dgamma(0.01, 0.01)
  sigma2 <- 1 / tau_residual

  tau_group ~ dexp(1)
}
"

# Write model to a temporary file
model_file <- tempfile(fileext=".bug")
cat(model_string, file = model_file)

##############################################################
# Initial values
##############################################################
inits <- function() {
  list(
    beta0 = 0,
    beta = rep(0, P),
    u = rep(0, J_train),
    tau_residual = 0.5,
    tau_group = 1
  )
}

##############################################################
# Run the model on the training data
##############################################################
model <- jags.model(model_file, data = jags_data, inits = inits, n.chains = 3, n.adapt = 1000)
update(model, 4000) # Burn-in

samples <- coda.samples(model, variable.names = c("beta0", "beta", "u", "sigma2", "tau_group"), n.iter = 100000)

##############################################################
# Posterior summaries and convergence checks
##############################################################
print("Summary of posterior (after burn-in):")
summary(samples)

par(mar = c(2,2,2,2))
plot(samples, density=FALSE, trace=TRUE, auto.layout = TRUE , ask=FALSE)

autocorr.plot(samples[[1]])
gelman_results <- gelman.diag(samples, autoburnin=FALSE)
gelman.plot(samples, autoburnin=FALSE)
print(gelman_results)

##############################################################
# WAIC Calculation
# We need to sample the 'likelihood' node from the model
##############################################################
samples_likelihood <- coda.samples(model, variable.names=c("likelihood"), n.iter=10000)

# Combine likelihood for all chains
likelihood_chains <- do.call(rbind, samples_likelihood)

# fbar: posterior mean of likelihood per datapoint
fbar <- colMeans(likelihood_chains)

# Remove any variable named 'var' to allow 'var' function usage
#rm(var)

# Column-wise variance of log(likelihood)
pW <- sum(apply(log(likelihood_chains), 2, var))

# WAIC
WAIC <- -2 * sum(log(fbar)) + 2 * pW
#cat("WAIC:", WAIC, "\n")
print("WAIC:")
print(WAIC)


##############################################################
# Extract posterior means for prediction on TEST set
##############################################################
posterior_mat <- as.matrix(samples)
beta0_post <- posterior_mat[,"beta0"]
beta_post <- posterior_mat[,grep("^beta\\[", colnames(posterior_mat))]
u_indices <- grep("^u\\[", colnames(posterior_mat))
u_post <- posterior_mat[, u_indices]

# Posterior means
beta0_hat <- mean(beta0_post)
beta_hat <- apply(beta_post, 2, mean)
u_hat <- apply(u_post, 2, mean)

##############################################################
# Predict on test set
##############################################################
# Note: test groups must align with train groups indexing
# If some test group doesn't appear in training, it will be an issue. 
# Assuming all test groups appear in train:
group_test <- obesity_test$group
y_test <- obesity_test$BMI_squared

y_pred <- beta0_hat + X_test %*% beta_hat + u_hat[group_test]

y_pred <- as.numeric(y_pred)

##############################################################
# Compute R² on test set
##############################################################
# R² = 1 - SS_res/SS_tot
SS_res <- sum((y_test - y_pred)^2)
SS_tot <- sum((y_test - mean(y_test))^2)
R2_test <- 1 - (SS_res/SS_tot)

print("R² on Test Set:")
print(R2_test)

##############################################################
# DONE
##############################################################

```


```{r}
##############################################################
# Full R Script: 
# 1. Load and Prepare Data 
# 2. Split into Train and Test 
# 3. Run Bayesian Model (JAGS) on the Train Set 
# 4. Predict on Test Set and Compute R²
##############################################################

# Clear workspace
rm(list=ls())

##############################################################
# Load required libraries
##############################################################
library(ggplot2)     # For visualizations
library(dplyr)        # For data manipulation
library(rjags)        # For JAGS interface
library(coda)         # For MCMC diagnostics

##############################################################
# Read the data
##############################################################
file_path <- "C:/Users/chopr/Desktop/Statistics Subjects/STAT431-ThisYear/project/dataset/obesity_dataset_linear.csv"
obesity_data <- read.csv(file_path)

# Display the first few rows of the dataframe
head(obesity_data)

##############################################################
# Create BMI column (BMI = Weight / Height^2)
##############################################################
obesity_data <- obesity_data %>%
  mutate(BMI_cont = Weight / (Height ^ 2)) %>%
  mutate(BMI_squared = BMI_cont ^ 2) %>%
  select(-CALC, -CAEC) # Dropping specified columns

head(obesity_data)

##############################################################
# Convert select variables into factors
##############################################################
factor_vars <- c("Gender", "family_history_with_overweight", "FAVC", 
                 "SMOKE", "SCC", "MTRANS", "NObeyesdad")
obesity_data[factor_vars] <- lapply(obesity_data[factor_vars], factor)

str(obesity_data)

##############################################################
# Exploratory Plots (optional - won't affect functionality)
##############################################################
# Numeric and categorical variable distribution checks
numeric_vars <- sapply(obesity_data, is.numeric)
categorical_vars <- sapply(obesity_data, is.factor)

numeric_var_names <- names(obesity_data)[numeric_vars]
categorical_var_names <- names(obesity_data)[categorical_vars]

##############################################################
# Drop Weight, NObeyesdad columns as previously done
##############################################################
obesity_data <- obesity_data %>%
  select(-Weight, -NObeyesdad)

head(obesity_data)


##############################################################
# Data Preparation for JAGS
# Steps:
# 1. Convert categorical features to numeric (0-based)
# 2. Scale and standardize numeric features as before
# 3. Create predictor matrix X
##############################################################

# Convert categorical features to numeric (0-based)
categorical_features <- c("Gender", "family_history_with_overweight", "FAVC","SMOKE", "SCC", "MTRANS")
obesity_data[categorical_features] <- lapply(obesity_data[categorical_features], function(x) {
  numeric_values <- as.numeric(factor(x))
  numeric_values - min(numeric_values, na.rm = TRUE)
})

# Identify columns to scale (excluding Age, BMI_cont, group, MTRANS because group/MTRANS used for grouping)
columns_to_scale <- setdiff(names(obesity_data), c("Age", "BMI_squared", "group", "MTRANS"))

# Min-max scaling for selected columns
obesity_data[columns_to_scale] <- lapply(obesity_data[columns_to_scale], function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
})

# Standardize Age
obesity_data <- obesity_data %>%
  mutate(
    Age = (Age - mean(Age, na.rm = TRUE)) / sd(Age, na.rm = TRUE)
  )

# Define predictors
predictors <- c("Age", "Gender", "family_history_with_overweight", "FAVC",
                "SMOKE", "SCC", "FAF", "TUE", "CH2O", "NCP", "FCVC")

X <- as.matrix(obesity_data[, predictors])

# Create a group variable from MTRANS
obesity_data$group <- obesity_data$MTRANS  
obesity_data$group <- as.integer(as.factor(obesity_data$group))

# Final structure
N <- nrow(obesity_data)
P <- ncol(X)
J <- length(unique(obesity_data$group))

str(obesity_data)
cat("Dimensions of X:", dim(X), "\n")
cat("Number of Observations (N):", N, "\n")
cat("Number of Groups (J):", J, "\n")
cat("Number of Predictors (P):", P, "\n")

##############################################################
# Train-Test Split
##############################################################
set.seed(123) # For reproducibility
train_index <- sample(1:N, size = floor(0.7*N), replace = FALSE)
test_index <- setdiff(1:N, train_index)

obesity_train <- obesity_data[train_index, ]
obesity_test <- obesity_data[test_index, ]

X_train <- X[train_index, ]
X_test <- X[test_index, ]

N_train <- nrow(X_train)
N_test <- nrow(X_test)

J_train <- length(unique(obesity_train$group))
# Note: It's possible that test set doesn't have all groups present in training.
# For simplicity, we assume all groups in test are also in train.
# If not, you'd have to handle groups not seen in training (set u[group] = 0 or similar).

##############################################################
# Prepare Data for JAGS from the Training Set
##############################################################
jags_data <- list(
  N = N_train,
  J = J_train,
  BMI_squared = obesity_train$BMI_squared,
  X = X_train,
  group = obesity_train$group
)

##############################################################
# JAGS Model File (question_3.bug)
# We'll write it here as a temporary file
##############################################################
model_string <- "
model {
  # Likelihood
  for (i in 1:N) {
    BMI_squared[i] ~ dnorm(mu[i], tau_residual)
    mu[i] <- beta0 + inprod(X[i, ], beta[]) + u[group[i]]
    # For WAIC calculation
    likelihood[i] <- dnorm(BMI_squared[i], mu[i], tau_residual)
  }

  # Group effects
  for (j in 1:J) {
    u[j] ~ dnorm(0, tau_group)
  }

  # Priors for coefficients
  beta0 ~ dnorm(0, 0.001)

  beta[1] ~ dnorm(0, 0.001) # Age
  beta[2] ~ dnorm(0, 0.001) # Gender
  beta[3] ~ dnorm(0, 0.001) # family_history_with_overweight
  beta[4] ~ dnorm(0, 0.001) # FAVC
  beta[5] ~ dnorm(0, 0.001) # SMOKE
  beta[6] ~ dnorm(0, 0.001) # SCC
  beta[7] ~ dnorm(0, 0.001) # FAF
  beta[8] ~ dnorm(0, 0.000001) # TUE
  beta[9] ~ dnorm(0, 0.000001) # CH2O
  beta[10] ~ dnorm(0, 0.001) # NCP
  beta[11] ~ dnorm(0, 0.001) # FCVC

  # Priors for variance
  tau_residual ~ dgamma(0.01, 0.01)
  sigma2 <- 1 / tau_residual

  tau_group ~ dexp(1)
}
"

# Write model to a temporary file
model_file <- tempfile(fileext=".bug")
cat(model_string, file = model_file)

##############################################################
# Initial values
##############################################################
inits <- function() {
  list(
    beta0 = 0,
    beta = rep(0, P),
    u = rep(0, J_train),
    tau_residual = 0.5,
    tau_group = 1
  )
}

##############################################################
# Run the model on the training data
##############################################################
model <- jags.model(model_file, data = jags_data, inits = inits, n.chains = 3, n.adapt = 5000)
update(model, 4000) # Burn-in

samples <- coda.samples(model, variable.names = c("beta0", "beta", "u", "sigma2", "tau_group"), n.iter = 100000)

##############################################################
# Posterior summaries and convergence checks
##############################################################
print("Summary of posterior (after burn-in):")
summary(samples)

par(mar = c(2,2,2,2))
plot(samples, density=FALSE, trace=TRUE, auto.layout = TRUE , ask=FALSE)

autocorr.plot(samples[[1]])
gelman_results <- gelman.diag(samples, autoburnin=FALSE)
gelman.plot(samples, autoburnin=FALSE)
print(gelman_results)

##############################################################
# WAIC Calculation
# We need to sample the 'likelihood' node from the model
##############################################################
samples_likelihood <- coda.samples(model, variable.names=c("likelihood"), n.iter=10000)

# Combine likelihood for all chains
likelihood_chains <- do.call(rbind, samples_likelihood)

# fbar: posterior mean of likelihood per datapoint
fbar <- colMeans(likelihood_chains)

# Remove any variable named 'var' to allow 'var' function usage
#rm(var)

# Column-wise variance of log(likelihood)
pW <- sum(apply(log(likelihood_chains), 2, var))

# WAIC
WAIC <- -2 * sum(log(fbar)) + 2 * pW
cat("WAIC:", WAIC, "\n")
print("WAIC:")
print(WAIC)


##############################################################
# Extract posterior means for prediction on TEST set
##############################################################
posterior_mat <- as.matrix(samples)
beta0_post <- posterior_mat[,"beta0"]
beta_post <- posterior_mat[,grep("^beta\\[", colnames(posterior_mat))]
u_indices <- grep("^u\\[", colnames(posterior_mat))
u_post <- posterior_mat[, u_indices]

# Posterior means
beta0_hat <- mean(beta0_post)
beta_hat <- apply(beta_post, 2, mean)
u_hat <- apply(u_post, 2, mean)

##############################################################
# Predict on test set
##############################################################
# Note: test groups must align with train groups indexing
# If some test group doesn't appear in training, it will be an issue. 
# Assuming all test groups appear in train:
group_test <- obesity_test$group
y_test <- obesity_test$BMI_squared

y_pred <- beta0_hat + X_test %*% beta_hat + u_hat[group_test]

y_pred <- as.numeric(y_pred)

##############################################################
# Compute R² on test set
##############################################################
# R² = 1 - SS_res/SS_tot
SS_res <- sum((y_test - y_pred)^2)
SS_tot <- sum((y_test - mean(y_test))^2)
R2_test <- 1 - (SS_res/SS_tot)

cat("R² on Test Set:", R2_test, "\n")
print("R² on Test Set:")
print(R2_test)

##############################################################
# DONE
##############################################################

```


```{r}
##############################################################
# Full R Script: 
# 1. Load and Prepare Data 
# 2. Split into Train and Test 
# 3. Run Bayesian Model (JAGS) on the Train Set 
# 4. Predict on Test Set and Compute R²
# 5. Compute WAIC
# 6. Heavy-tailed (t-distribution) priors for regression coefficients
##############################################################

# Clear workspace
rm(list=ls())

##############################################################
# Load required libraries
##############################################################
library(ggplot2)     # For visualizations
library(dplyr)        # For data manipulation
library(rjags)        # For JAGS interface
library(coda)         # For MCMC diagnostics

##############################################################
# Read the data
##############################################################
file_path <- "C:/Users/chopr/Desktop/Statistics Subjects/STAT431-ThisYear/project/dataset/obesity_dataset_linear.csv"
obesity_data <- read.csv(file_path)

# Display the first few rows of the dataframe
head(obesity_data)

##############################################################
# Create BMI column (BMI = Weight / Height^2)
##############################################################
obesity_data <- obesity_data %>%
  mutate(BMI_cont = Weight / (Height ^ 2)) %>%
  mutate(BMI_squared = BMI_cont ^ 2) %>%
  select(-CALC, -CAEC) # Dropping specified columns

head(obesity_data)

##############################################################
# Convert select variables into factors
##############################################################
factor_vars <- c("Gender", "family_history_with_overweight", "FAVC", 
                 "SMOKE", "SCC", "MTRANS", "NObeyesdad")
obesity_data[factor_vars] <- lapply(obesity_data[factor_vars], factor)

str(obesity_data)

##############################################################
# Drop Weight, NObeyesdad columns as previously done
##############################################################
obesity_data <- obesity_data %>%
  select(-Weight, -NObeyesdad)

head(obesity_data)

##############################################################
# Data Preparation for JAGS
# Steps:
# 1. Convert categorical features to numeric (0-based)
# 2. Scale and standardize numeric features as before
# 3. Create predictor matrix X
##############################################################

# Convert categorical features to numeric (0-based)
categorical_features <- c("Gender", "family_history_with_overweight", "FAVC","SMOKE", "SCC", "MTRANS")
obesity_data[categorical_features] <- lapply(obesity_data[categorical_features], function(x) {
  numeric_values <- as.numeric(factor(x))
  numeric_values - min(numeric_values, na.rm = TRUE)
})

# Identify columns to scale (excluding Age, BMI_squared, group, MTRANS)
columns_to_scale <- setdiff(names(obesity_data), c("Age", "BMI_squared", "group", "MTRANS"))

# Min-max scaling for selected columns
obesity_data[columns_to_scale] <- lapply(obesity_data[columns_to_scale], function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
})

# Standardize Age
obesity_data <- obesity_data %>%
  mutate(
    Age = (Age - mean(Age, na.rm = TRUE)) / sd(Age, na.rm = TRUE)
  )

# Define predictors
predictors <- c("Age", "Gender", "family_history_with_overweight", "FAVC",
                "SMOKE", "SCC", "FAF", "TUE", "CH2O", "NCP", "FCVC")

X <- as.matrix(obesity_data[, predictors])

# Create a group variable from MTRANS
obesity_data$group <- obesity_data$MTRANS  
obesity_data$group <- as.integer(as.factor(obesity_data$group))

# Final structure
N <- nrow(obesity_data)
P <- ncol(X)
J <- length(unique(obesity_data$group))

str(obesity_data)
cat("Dimensions of X:", dim(X), "\n")
cat("Number of Observations (N):", N, "\n")
cat("Number of Groups (J):", J, "\n")
cat("Number of Predictors (P):", P, "\n")

##############################################################
# Train-Test Split
##############################################################
set.seed(123) # For reproducibility
train_index <- sample(1:N, size = floor(0.7*N), replace = FALSE)
test_index <- setdiff(1:N, train_index)

obesity_train <- obesity_data[train_index, ]
obesity_test <- obesity_data[test_index, ]

X_train <- X[train_index, ]
X_test <- X[test_index, ]

N_train <- nrow(X_train)
N_test <- nrow(X_test)

J_train <- length(unique(obesity_train$group))

##############################################################
# Prepare Data for JAGS from the Training Set
##############################################################
jags_data <- list(
  N = N_train,
  J = J_train,
  BMI_squared = obesity_train$BMI_squared,
  X = X_train,
  group = obesity_train$group
)

##############################################################
# JAGS Model File
# Updated to use t-distribution (dt) priors for coefficients
##############################################################
model_string <- "
model {
  # Likelihood
  for (i in 1:N) {
    BMI_squared[i] ~ dnorm(mu[i], tau_residual)
    mu[i] <- beta0 + inprod(X[i, ], beta[]) + u[group[i]]
    # For WAIC calculation
    likelihood[i] <- dnorm(BMI_squared[i], mu[i], tau_residual)
  }

  # Group effects
  for (j in 1:J) {
    u[j] ~ dnorm(0, tau_group)
  }

  # Priors for coefficients (heavy-tailed t-distribution)
  # dt(mu, tau, df)
  # Using df=3 for a moderate heavy-tailed distribution
  # tau=1 implies standard deviation ~1 for the t-distribution
  # Priors for coefficients
  beta0 ~ dnorm(0, 0.001)

  beta[1] ~ dt(0, 1000, 10) # Age
  beta[2] ~ dnorm(0, 0.001) # Gender
  beta[3] ~ dnorm(0, 0.001) # family_history_with_overweight
  beta[4] ~ dnorm(0, 0.001) # FAVC
  beta[5] ~ dnorm(0, 0.001) # SMOKE
  beta[6] ~ dnorm(0, 0.001) # SCC
  beta[7] ~ dnorm(0, 0.001) # FAF
  beta[8] ~ dt(0, 100,7) # TUE
  beta[9] ~ dt(0, 1000,10) # CH2O
  beta[10] ~ dnorm(0, 0.001) # NCP
  beta[11] ~ dnorm(0, 0.001) # FCVC

  # Priors for variance
  tau_residual ~ dgamma(0.01, 0.01)
  sigma2 <- 1 / tau_residual

  tau_group ~ dexp(1)
}
"

# Write model to a temporary file
model_file <- tempfile(fileext=".bug")
cat(model_string, file = model_file)

##############################################################
# Initial values
##############################################################
inits <- function() {
  list(
    beta0 = 20,
    beta = rep(0, P), 
    u = rep(0, J_train),
    tau_residual = 1,
    tau_group = 1
  )
}

##############################################################
# Run the model on the training data
##############################################################
model <- jags.model(model_file, data = jags_data, inits = inits, n.chains = 3, n.adapt = 2000)
update(model, 2000) # Burn-in

samples <- coda.samples(model, variable.names = c("beta0", "beta", "u", "sigma2", "tau_group"), n.iter = 20000)

##############################################################
# Posterior summaries and convergence checks
##############################################################
print("Summary of posterior (after burn-in):")
summary(samples)

# Diagnostics (optional)
# par(mar = c(2,2,2,2))
# plot(samples, density=FALSE, trace=TRUE, auto.layout = TRUE , ask=FALSE)
autocorr.plot(samples[[1]])
gelman_results <- gelman.diag(samples, autoburnin=FALSE)
# gelman.plot(samples, autoburnin=FALSE)
print(gelman_results)

##############################################################
# WAIC Calculation
##############################################################
samples_likelihood <- coda.samples(model, variable.names=c("likelihood"), n.iter=20000)

# Combine likelihood for all chains
likelihood_chains <- do.call(rbind, samples_likelihood)

# fbar: posterior mean of likelihood per datapoint
fbar <- colMeans(likelihood_chains)

# Column-wise variance of log(likelihood)
pW <- sum(apply(log(likelihood_chains), 2, var))

# WAIC
WAIC <- -2 * sum(log(fbar)) + 2 * pW
cat("WAIC:", WAIC, "\n")
print("WAIC:")
print(WAIC)


##############################################################
# Extract posterior means for prediction on TEST set
##############################################################
posterior_mat <- as.matrix(samples)
beta0_post <- posterior_mat[,"beta0"]
beta_post <- posterior_mat[,grep("^beta\\[", colnames(posterior_mat))]
u_indices <- grep("^u\\[", colnames(posterior_mat))
u_post <- posterior_mat[, u_indices]

# Posterior means
beta0_hat <- mean(beta0_post)
beta_hat <- apply(beta_post, 2, mean)
u_hat <- apply(u_post, 2, mean)

##############################################################
# Predict on test set
##############################################################
group_test <- obesity_test$group
y_test <- obesity_test$BMI_squared

y_pred <- beta0_hat + X_test %*% beta_hat + u_hat[group_test]
y_pred <- as.numeric(y_pred)

##############################################################
# Compute R² on test set
##############################################################
SS_res <- sum((y_test - y_pred)^2)
SS_tot <- sum((y_test - mean(y_test))^2)
R2_test <- 1 - (SS_res/SS_tot)
cat("R² on Test Set:", R2_test, "\n")
print("R² on Test Set:")
print(R2_test)


##############################################################
# DONE
##############################################################

```